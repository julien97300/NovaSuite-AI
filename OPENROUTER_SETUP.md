# ğŸ¤– Configuration OpenRouter pour NovaSuite AI

## ğŸ“‹ Qu'est-ce qu'OpenRouter ?

**OpenRouter** est une plateforme qui donne accÃ¨s Ã  plusieurs modÃ¨les d'IA (Claude, GPT, Llama, etc.) via une seule API. C'est une excellente alternative Ã  OpenAI qui offre :

- ğŸ¯ **AccÃ¨s Ã  plusieurs modÃ¨les** : Claude 3, GPT-4, Llama 2, Mistral, etc.
- ğŸ’° **Prix compÃ©titifs** : Souvent moins cher qu'OpenAI direct
- ğŸ”„ **FlexibilitÃ©** : Changement de modÃ¨le sans changer de code
- ğŸš€ **Performance** : API rapide et fiable
- ğŸ“Š **Transparence** : Prix et usage clairement affichÃ©s

## ğŸ”‘ Obtenir une ClÃ© API OpenRouter

### 1. CrÃ©er un Compte
1. Allez sur [openrouter.ai](https://openrouter.ai)
2. Cliquez sur **"Sign Up"**
3. CrÃ©ez votre compte avec email/mot de passe ou GitHub

### 2. Obtenir la ClÃ© API
1. Connectez-vous Ã  votre compte
2. Allez dans **"API Keys"** dans le menu
3. Cliquez sur **"Create Key"**
4. Donnez un nom Ã  votre clÃ© (ex: "NovaSuite AI")
5. Copiez la clÃ© gÃ©nÃ©rÃ©e (format: `sk-or-v1-...`)

### 3. Ajouter des CrÃ©dits
1. Allez dans **"Credits"**
2. Ajoutez des crÃ©dits (minimum $5)
3. Les prix sont trÃ¨s compÃ©titifs (ex: Claude 3 Haiku ~$0.25/1M tokens)

## âš™ï¸ Configuration dans NovaSuite AI

### 1. Backend Configuration

Ã‰ditez le fichier `backend/.env` :

```bash
# OpenRouter API (pour l'IA) - AccÃ¨s Ã  Claude, GPT, Llama, etc.
OPENROUTER_API_KEY=sk-or-v1-votre-cle-ici
OPENROUTER_MODEL=anthropic/claude-3-haiku

# Optionnel : modÃ¨les alternatifs
# OPENROUTER_MODEL=openai/gpt-4-turbo
# OPENROUTER_MODEL=meta-llama/llama-2-70b-chat
# OPENROUTER_MODEL=mistralai/mistral-7b-instruct
```

### 2. ModÃ¨les RecommandÃ©s

| ModÃ¨le | Prix | Vitesse | QualitÃ© | Usage RecommandÃ© |
|--------|------|---------|---------|------------------|
| `anthropic/claude-3-haiku` | ğŸ’° TrÃ¨s bon marchÃ© | âš¡ TrÃ¨s rapide | â­â­â­ | Chat quotidien, corrections |
| `anthropic/claude-3-sonnet` | ğŸ’°ğŸ’° ModÃ©rÃ© | âš¡âš¡ Rapide | â­â­â­â­ | Documents complexes |
| `openai/gpt-4-turbo` | ğŸ’°ğŸ’°ğŸ’° Cher | âš¡âš¡ Rapide | â­â­â­â­â­ | TÃ¢ches critiques |
| `meta-llama/llama-2-70b-chat` | ğŸ’° Bon marchÃ© | âš¡âš¡ Rapide | â­â­â­ | Alternative open-source |

### 3. Configuration AvancÃ©e

Pour une configuration plus fine, Ã©ditez `backend/services/openRouterService.js` :

```javascript
// ModÃ¨les par dÃ©faut selon le type de tÃ¢che
const MODEL_CONFIG = {
  chat: 'anthropic/claude-3-haiku',        // Chat rapide et Ã©conomique
  correction: 'anthropic/claude-3-sonnet', // Correction prÃ©cise
  generation: 'openai/gpt-4-turbo',        // GÃ©nÃ©ration crÃ©ative
  formula: 'anthropic/claude-3-sonnet'     // Formules Excel
};
```

## ğŸš€ Test de Fonctionnement

### 1. Test Backend
```bash
# Dans le dossier backend
cd backend
npm start

# Test de l'endpoint
curl -X GET http://localhost:5000/api/ai/test \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

### 2. Test Frontend
1. Lancez l'application : `npm run dev`
2. Connectez-vous avec un compte
3. Ouvrez le chat NovaCopilot (bouton ğŸ¤–)
4. Tapez : "Bonjour, peux-tu me confirmer que tu fonctionnes ?"

### 3. VÃ©rification des Logs
```bash
# Logs backend pour voir les appels API
docker-compose logs -f backend

# Rechercher les logs OpenRouter
grep "OpenRouter" logs/backend.log
```

## ğŸ’¡ Optimisation des CoÃ»ts

### 1. Choix du ModÃ¨le
- **Claude 3 Haiku** : Le plus Ã©conomique pour usage quotidien
- **Claude 3 Sonnet** : Bon rapport qualitÃ©/prix
- **GPT-4 Turbo** : RÃ©servÃ© aux tÃ¢ches importantes

### 2. Limitation des Tokens
```javascript
// Dans openRouterService.js
const response = await axios.post(url, {
  model: this.defaultModel,
  messages: messages,
  max_tokens: 500,        // Limiter la rÃ©ponse
  temperature: 0.7,
  // Autres paramÃ¨tres...
});
```

### 3. Cache des RÃ©ponses
```javascript
// ImplÃ©menter un cache simple
const responseCache = new Map();

async chat(messages) {
  const cacheKey = JSON.stringify(messages);
  if (responseCache.has(cacheKey)) {
    return responseCache.get(cacheKey);
  }
  
  const response = await this.callAPI(messages);
  responseCache.set(cacheKey, response);
  return response;
}
```

## ğŸ”§ DÃ©pannage

### ProblÃ¨me : "API Key not found"
```bash
# VÃ©rifier la variable d'environnement
echo $OPENROUTER_API_KEY

# RedÃ©marrer le backend
docker-compose restart backend
```

### ProblÃ¨me : "Insufficient credits"
1. Allez sur [openrouter.ai/credits](https://openrouter.ai/credits)
2. Ajoutez des crÃ©dits Ã  votre compte
3. VÃ©rifiez votre usage dans le dashboard

### ProblÃ¨me : "Model not found"
```javascript
// Lister les modÃ¨les disponibles
const models = await openRouterService.getAvailableModels();
console.log(models);
```

### ProblÃ¨me : RÃ©ponses lentes
1. Changez pour un modÃ¨le plus rapide (Claude 3 Haiku)
2. RÃ©duisez `max_tokens`
3. VÃ©rifiez votre connexion internet

## ğŸ“Š Monitoring et Usage

### 1. Dashboard OpenRouter
- Allez sur [openrouter.ai/activity](https://openrouter.ai/activity)
- Surveillez votre usage en temps rÃ©el
- Analysez les coÃ»ts par modÃ¨le

### 2. Logs NovaSuite AI
```bash
# Voir les statistiques d'usage
grep "usage" logs/backend.log | tail -20

# Voir les erreurs API
grep "OpenRouter.*Error" logs/backend.log
```

### 3. Alertes de CoÃ»t
```javascript
// Dans openRouterService.js - ajouter une vÃ©rification
if (result.usage && result.usage.total_tokens > 1000) {
  console.warn(`High token usage: ${result.usage.total_tokens} tokens`);
}
```

## ğŸ¯ Bonnes Pratiques

### 1. SÃ©curitÃ©
- âœ… Ne jamais exposer la clÃ© API cÃ´tÃ© frontend
- âœ… Utiliser des variables d'environnement
- âœ… Rotation rÃ©guliÃ¨re des clÃ©s API
- âœ… Limitation des permissions par clÃ©

### 2. Performance
- âœ… Utiliser le modÃ¨le le plus adaptÃ© Ã  la tÃ¢che
- âœ… ImplÃ©menter un cache pour les rÃ©ponses frÃ©quentes
- âœ… Limiter la longueur des conversations
- âœ… Timeout appropriÃ© pour les requÃªtes

### 3. CoÃ»ts
- âœ… Surveiller l'usage quotidien
- âœ… DÃ©finir des limites de dÃ©penses
- âœ… Optimiser les prompts pour rÃ©duire les tokens
- âœ… Utiliser des modÃ¨les Ã©conomiques pour les tÃ¢ches simples

## ğŸ”„ Migration depuis OpenAI

Si vous avez dÃ©jÃ  une clÃ© OpenAI, vous pouvez utiliser les deux :

```bash
# Dans backend/.env
OPENROUTER_API_KEY=sk-or-v1-votre-cle-openrouter
OPENAI_API_KEY=sk-votre-cle-openai

# Le service utilisera OpenRouter en prioritÃ©
# et OpenAI en fallback si nÃ©cessaire
```

## ğŸ“ Support

### OpenRouter
- ğŸ“š Documentation : [openrouter.ai/docs](https://openrouter.ai/docs)
- ğŸ’¬ Discord : [discord.gg/openrouter](https://discord.gg/openrouter)
- ğŸ“§ Email : support@openrouter.ai

### NovaSuite AI
- ğŸ› Issues GitHub : [github.com/julien97300/NovaSuite-AI/issues](https://github.com/julien97300/NovaSuite-AI/issues)
- ğŸ“– Documentation : Voir les fichiers README et guides

---

**ğŸ‰ FÃ©licitations ! Votre assistant IA NovaCopilot est maintenant alimentÃ© par OpenRouter !**

Vous avez accÃ¨s aux meilleurs modÃ¨les d'IA du marchÃ© avec une API unifiÃ©e et des prix compÃ©titifs. Profitez de votre suite bureautique intelligente ! ğŸš€
